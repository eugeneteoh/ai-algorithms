{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYSdm1PJboXBaj2pdLdLKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4201dc318734df993ca1132bff0ec10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a4f453d6fbe436b9110e0ce7d1ad2ca",
              "IPY_MODEL_d7af8715eacc4ebab563f6f3db132ecb",
              "IPY_MODEL_d49eb187fb0746499fb50766f5b7be15"
            ],
            "layout": "IPY_MODEL_690ea8e6ddf848a0a49b2e7afb701bcf"
          }
        },
        "8a4f453d6fbe436b9110e0ce7d1ad2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06b5f6a0add40db8653618f613420c5",
            "placeholder": "​",
            "style": "IPY_MODEL_30b000d108b74462a10f91e9cfdcc4ce",
            "value": "Epoch 0:  28%"
          }
        },
        "d7af8715eacc4ebab563f6f3db132ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43cc9f0c0e1041368869361e93af5cd5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8cfde446cb14451862d44bbbde1e5ff",
            "value": 28
          }
        },
        "d49eb187fb0746499fb50766f5b7be15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e20d0ae3bf55485fb80af6daebd17223",
            "placeholder": "​",
            "style": "IPY_MODEL_59eab4dd7b20409098a65694b7888fea",
            "value": " 28/100.0 [00:52&lt;02:15,  1.89s/it, loss=0.00216, v_num=0]"
          }
        },
        "690ea8e6ddf848a0a49b2e7afb701bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f06b5f6a0add40db8653618f613420c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b000d108b74462a10f91e9cfdcc4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43cc9f0c0e1041368869361e93af5cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8cfde446cb14451862d44bbbde1e5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e20d0ae3bf55485fb80af6daebd17223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59eab4dd7b20409098a65694b7888fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugeneteoh/ai-algorithms/blob/transformer/transformer/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://github.com/Atcold/pytorch-Deep-Learning/blob/master/15-transformer.ipynb\n",
        "\n",
        "https://nn.labml.ai/transformers"
      ],
      "metadata": {
        "id": "8RiVhHKos0vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchdata torchtext pytorch-lightning"
      ],
      "metadata": {
        "id": "MeIMc2erv64Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "PN2PSkBiT8TA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fyu7yTglSfW",
        "outputId": "2ac4c2a6-ea30-4d15-cf13-2c4c7ecbc9c6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model=512, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = self.d_v = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V):\n",
        "        A = Q @ K.transpose(2, 3)\n",
        "        A /= np.sqrt(self.d_k)\n",
        "        A = F.softmax(A, dim=-1)\n",
        "        attn = A @ V\n",
        "        return attn\n",
        "\n",
        "    def forward(self, X_q, X_k, X_v):\n",
        "        batch_size, seq_length, dim = X_q.shape\n",
        "\n",
        "        Q = self.W_q(X_q)\n",
        "        K = self.W_k(X_k)\n",
        "        V = self.W_v(X_v)\n",
        "\n",
        "        # Split heads\n",
        "        Q = Q.view(batch_size, self.num_heads, seq_length, self.d_k)\n",
        "        K = K.view(batch_size, self.num_heads, seq_length, self.d_k)\n",
        "        V = V.view(batch_size, self.num_heads, seq_length, self.d_v)\n",
        "\n",
        "        H_cat = self.scaled_dot_product_attention(Q, K, V)\n",
        "        H_cat = H_cat.view(batch_size, seq_length, dim)\n",
        "\n",
        "        out = self.W_o(H_cat)\n",
        "        return out\n",
        "\n",
        "mha = MultiHeadAttention()"
      ],
      "metadata": {
        "id": "-HByNhYJlbda"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_K = torch.tensor(\n",
        "    [[10, 0, 0],\n",
        "     [ 0,10, 0],\n",
        "     [ 0, 0,10],\n",
        "     [ 0, 0,10]]\n",
        ").float()[None,None]\n",
        "\n",
        "test_V = torch.tensor(\n",
        "    [[   1,0,0],\n",
        "     [  10,0,0],\n",
        "     [ 100,5,0],\n",
        "     [1000,6,0]]\n",
        ").float()[None,None]\n",
        "\n",
        "test_Q = torch.tensor(\n",
        "    [[0, 10, 0]]\n",
        ").float()[None, None]\n",
        "\n",
        "test_X_k = torch.randn((1, 1, 512))\n",
        "test_X_v = torch.randn((1, 1, 512))\n",
        "test_X_q = torch.randn((1, 1, 512))\n",
        "\n",
        "# Test scaled_dot_product_attention shape\n",
        "output = mha.scaled_dot_product_attention(test_Q, test_K, test_V)\n",
        "assert test_Q.shape == output.shape\n",
        "\n",
        "# Test mha output shape\n",
        "output = mha(test_X_q, test_X_k, test_X_v)\n",
        "assert test_X_q.shape == output.shape"
      ],
      "metadata": {
        "id": "cclUvbmLszOH"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model=512, num_heads=8, ff_hidden_dim=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, ff_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_dim, d_model)\n",
        "        )\n",
        "\n",
        "        self.layernorm1 = nn.LayerNorm(normalized_shape=d_model)\n",
        "        self.layernorm2 = nn.LayerNorm(normalized_shape=d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layernorm1(x + self.mha(x, x, x))\n",
        "        out = self.layernorm2(out + self.ff(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "bjDj52al9hS6"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, d_model=512, vocab_size=10000, max_len=5000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
        "        self.register_buffer(\"positional_encodings\", self.get_positional_encoding(d_model, max_len))\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def get_positional_encoding(self, d_model, max_len):\n",
        "        encodings = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        two_i = torch.arange(0, d_model, 2)\n",
        "        denominator = 10000 ** (two_i / d_model)\n",
        "        div = position / denominator\n",
        "        encodings[:, 0::2] = torch.sin(div)\n",
        "        encodings[:, 1::2] = torch.cos(div)\n",
        "        encodings.requires_grad_(False)\n",
        "\n",
        "        return encodings\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_length = x.shape[1]\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=x.device) # (max_seq_length)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(x)                      # (bs, max_seq_length)\n",
        "\n",
        "        word_embeddings = self.word_embeddings(x)\n",
        "\n",
        "        embeddings = word_embeddings + self.positional_encodings\n",
        "        \n",
        "        return self.layernorm(embeddings)\n"
      ],
      "metadata": {
        "id": "7dkGQL3d7nha"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size=10000, max_seq_len=5000, num_layers=6, d_model=512, num_heads=8, ff_hidden_dim=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_layer = Embedding(d_model=d_model, vocab_size=vocab_size, max_len=max_seq_len)\n",
        "        self.enc_layers = nn.Sequential(*[EncoderLayer(d_model=d_model, num_heads=num_heads, ff_hidden_dim=ff_hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding_layer(x)\n",
        "        return self.enc_layers(x)\n"
      ],
      "metadata": {
        "id": "x4Yl2K014Z_N"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, num_outputs, vocab_size=10000, max_seq_len=5000, num_layers=6, d_model=512, num_heads=8, ff_hidden_dim=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(\n",
        "            vocab_size=vocab_size, max_seq_len=max_seq_len, num_layers=num_layers, d_model=d_model, num_heads=num_heads, ff_hidden_dim=ff_hidden_dim\n",
        "        )\n",
        "        self.dense = nn.Linear(d_model, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x, _ = torch.max(x, dim=1)\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Puch1PUO-WGv"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import AG_NEWS, IMDB\n",
        "from collections import Counter\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.functional import truncate, to_tensor\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchtext.transforms as T\n"
      ],
      "metadata": {
        "id": "P7-FUUXZvv3X"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')  \n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "counter = Counter()\n",
        "for (label, line) in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "data_vocab = vocab(counter, min_freq = 1, specials=('\\<unk\\>', '\\<BOS\\>', '\\<EOS\\>', '\\<PAD\\>'))\n",
        "\n",
        "batch_size = 64\n",
        "max_seq_len = 256\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    T.VocabTransform(data_vocab),\n",
        "    T.Truncate(max_seq_len),\n",
        "    T.ToTensor(),\n",
        "    T.PadTransform(max_seq_len, 1),\n",
        ")\n",
        "text_pipeline = lambda x: text_transform(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "apply_transform = lambda x: (label_pipeline(x[0]), text_pipeline(x[1]))\n",
        "\n",
        "train_iter = train_iter.map(apply_transform)\n",
        "train_iter = train_iter.batch(batch_size)\n",
        "train_iter = train_iter.rows2columnar([\"target\", \"token_ids\"])\n",
        "train_loader = DataLoader(train_iter, batch_size=None)"
      ],
      "metadata": {
        "id": "9shF8CGQCidT"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = TransformerClassifier(num_outputs=2, vocab_size=len(data_vocab), max_seq_len=max_seq_len)\n",
        "\n",
        "for i, batch in enumerate(train_loader):\n",
        "    targets = batch[\"target\"]\n",
        "    token_ids = torch.stack(batch[\"token_ids\"])\n",
        "\n",
        "    out = classifier(token_ids)\n",
        "    print(out.shape)\n",
        "    if i == 0:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5p8pXwY9DPp",
        "outputId": "878c468e-b4e9-4738-f7a6-0829e1dc2a7e"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "StDiz2reAyjQ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifierLT(pl.LightningModule):\n",
        "    def __init__(self, num_outputs, vocab_size=10000, max_seq_len=5000, num_layers=6, d_model=512, num_heads=8, ff_hidden_dim=2048):\n",
        "        super().__init__()\n",
        "        self.classifier = TransformerClassifier(\n",
        "            num_outputs=num_outputs,\n",
        "            vocab_size=vocab_size,\n",
        "            max_seq_len=max_seq_len,\n",
        "            num_layers=num_layers,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            ff_hidden_dim=ff_hidden_dim\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        targets = torch.as_tensor(batch[\"target\"])\n",
        "        token_ids = torch.stack(batch[\"token_ids\"])\n",
        "\n",
        "        out = self.classifier(token_ids)\n",
        "\n",
        "        loss = F.cross_entropy(out, targets)\n",
        "\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "classifier = TransformerClassifierLT(num_outputs=2, vocab_size=len(data_vocab), max_seq_len=max_seq_len, num_layers=2, d_model=32, num_heads=4)"
      ],
      "metadata": {
        "id": "C_c_g-FLEhAj"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(limit_train_batches=100, max_epochs=1)\n",
        "trainer.fit(model=classifier, train_dataloaders=train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335,
          "referenced_widgets": [
            "c4201dc318734df993ca1132bff0ec10",
            "8a4f453d6fbe436b9110e0ce7d1ad2ca",
            "d7af8715eacc4ebab563f6f3db132ecb",
            "d49eb187fb0746499fb50766f5b7be15",
            "690ea8e6ddf848a0a49b2e7afb701bcf",
            "f06b5f6a0add40db8653618f613420c5",
            "30b000d108b74462a10f91e9cfdcc4ce",
            "43cc9f0c0e1041368869361e93af5cd5",
            "c8cfde446cb14451862d44bbbde1e5ff",
            "e20d0ae3bf55485fb80af6daebd17223",
            "59eab4dd7b20409098a65694b7888fea"
          ]
        },
        "id": "P3jYv-mrFUbo",
        "outputId": "8625bf90-e894-4faa-b1a7-abfb17bac373"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type                  | Params\n",
            "-----------------------------------------------------\n",
            "0 | classifier | TransformerClassifier | 3.5 M \n",
            "-----------------------------------------------------\n",
            "3.5 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.5 M     Total params\n",
            "13.988    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4201dc318734df993ca1132bff0ec10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GMp0gnCTQ8g5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}